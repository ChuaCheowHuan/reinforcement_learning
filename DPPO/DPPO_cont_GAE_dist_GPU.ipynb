{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DPPO_cont_GAE_dist_GPU.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0qpSpGKP0_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Distributed Proximal Policy Optimization (Distributed PPO or DPPO) continuous \n",
        "version implementation with distributed Tensorflow and Python’s multiprocessing \n",
        "package. This implementation uses normalized running rewards with GAE. The code \n",
        "is tested with Gym’s continuous action space environment, Pendulum-v0 on Colab.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "#!pip install -q tf-nightly"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93E4LcmdiYsV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.reset_default_graph()\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import gym\n",
        "import time\n",
        "from multiprocessing import Process"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFfwwCjNibWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The following class is adapted from OpenAI's baseline:\n",
        "# https://github.com/openai/baselines/blob/master/baselines/common/running_mean_std.py\n",
        "# https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Parallel_algorithm\n",
        "# This class is used for the normalization of rewards in this program before GAE computation.\n",
        "class RunningStats(object):\n",
        "    def __init__(self, epsilon=1e-4, shape=()):\n",
        "        self.mean = np.zeros(shape, 'float64')\n",
        "        self.var = np.ones(shape, 'float64')\n",
        "        self.std = np.ones(shape, 'float64')\n",
        "        self.count = epsilon\n",
        "\n",
        "    def update(self, x):\n",
        "        batch_mean = np.mean(x, axis=0)\n",
        "        batch_var = np.var(x, axis=0)\n",
        "        batch_count = x.shape[0]\n",
        "        self.update_from_moments(batch_mean, batch_var, batch_count)\n",
        "\n",
        "    def update_from_moments(self, batch_mean, batch_var, batch_count):\n",
        "        delta = batch_mean - self.mean\n",
        "        new_mean = self.mean + delta * batch_count / (self.count + batch_count)\n",
        "        m_a = self.var * self.count\n",
        "        m_b = batch_var * batch_count\n",
        "        M2 = m_a + m_b + np.square(delta) * self.count * batch_count / (self.count + batch_count)\n",
        "        new_var = M2 / (self.count + batch_count)\n",
        "\n",
        "        self.mean = new_mean\n",
        "        self.var = new_var\n",
        "        self.std = np.maximum(np.sqrt(self.var), 1e-6)\n",
        "        self.count = batch_count + self.count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNuMXS_T2QkB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PPO(object):    \n",
        "    def __init__(self, scope, sess, env, global_PPO=None):    \n",
        "        self.sess = sess\n",
        "        self.env = env\n",
        "        #OPT_A = tf.train.AdamOptimizer(A_LR, beta1=0.99, beta2=0.999, name='OPT_A')\n",
        "        #OPT_C = tf.train.AdamOptimizer(C_LR, beta1=0.99, beta2=0.999, name='OPT_C')          \n",
        "        OPT_A = tf.train.AdamOptimizer(A_LR, name='OPT_A')\n",
        "        OPT_C = tf.train.AdamOptimizer(C_LR, name='OPT_C')          \n",
        "        \n",
        "        with tf.variable_scope(scope): # scope is either global or wid\n",
        "            self.state = tf.placeholder(tf.float32, [None, S_DIM], 'state')\n",
        "\n",
        "            # critic\n",
        "            with tf.variable_scope('critic'):\n",
        "                h1 = tf.layers.dense(self.state, hidden, tf.nn.relu, name='hidden', trainable=True)\n",
        "                self.val = tf.layers.dense(h1, 1, name='val', trainable=True)                \n",
        "                self.critic_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope + '/critic')\n",
        "                self.discounted_r = tf.placeholder(tf.float32, [None, 1], 'discounted_r')\n",
        "                self.advantage = self.discounted_r - self.val\n",
        "                self.closs = tf.reduce_mean(tf.square(self.advantage))\n",
        "                self.ctrain_op = OPT_C.minimize(self.closs)\n",
        "            with tf.variable_scope('cgrads'):\n",
        "                self.critic_grad_op = tf.gradients(self.closs, self.critic_params)\n",
        "\n",
        "            # actor\n",
        "            self.pi, self.pi_params = self._build_anet(scope, 'pi', self.env, trainable=True)\n",
        "            self.oldpi, self.oldpi_params = self._build_anet(scope, 'oldpi', self.env, trainable=True)  # originally trainable=False\n",
        "            with tf.variable_scope('sample_action'):\n",
        "                self.sample_op = tf.squeeze(self.pi.sample(1), axis=0) # choosing action\n",
        "            with tf.variable_scope('update_oldpi'):\n",
        "                self.update_oldpi_op = [oldp.assign(p) for p, oldp in zip(self.pi_params, self.oldpi_params)]\n",
        "            self.act = tf.placeholder(tf.float32, [None, A_DIM], 'action')\n",
        "            self.adv = tf.placeholder(tf.float32, [None, 1], 'advantage')\n",
        "            with tf.variable_scope('loss'):\n",
        "                with tf.variable_scope('surrogate'):\n",
        "                    ratio = self.pi.prob(self.act) / self.oldpi.prob(self.act)\n",
        "                    surr = ratio * self.adv\n",
        "                    self.aloss = -tf.reduce_mean(tf.minimum(surr, tf.clip_by_value(ratio, 1.-epsilon, 1.+epsilon)*self.adv))\n",
        "            with tf.variable_scope('atrain'):\n",
        "                self.atrain_op = OPT_A.minimize(self.aloss)\n",
        "            with tf.variable_scope('agrads'):\n",
        "                self.pi_grad_op = tf.gradients(self.aloss, self.pi_params)\n",
        "                \n",
        "            if scope != net_scope: # not global    \n",
        "                with tf.name_scope('params'): # push/pull from local/worker perspective\n",
        "                    with tf.name_scope('push_to_global'):\n",
        "                        self.push_actor_pi_params = OPT_A.apply_gradients(zip(self.pi_grad_op, global_PPO.pi_params))\n",
        "                        self.push_critic_params = OPT_C.apply_gradients(zip(self.critic_grad_op, global_PPO.critic_params))\n",
        "                    with tf.name_scope('pull_fr_global'):\n",
        "                        self.pull_actor_pi_params = [local_params.assign(global_params) for local_params, global_params in zip(self.pi_params, global_PPO.pi_params)]\n",
        "                        self.pull_critic_params = [local_params.assign(global_params) for local_params, global_params in zip(self.critic_params, global_PPO.critic_params)]                    \n",
        "                \n",
        "    def update(self, s, a, r, adv):\n",
        "        self.sess.run(self.update_oldpi_op)\n",
        "\n",
        "        for _ in range(A_EPOCH): # train actor\n",
        "            self.sess.run(self.atrain_op, {self.state: s, self.act: a, self.adv: adv})\n",
        "            # update actor\n",
        "            self.sess.run([self.push_actor_pi_params, \n",
        "                           self.pull_actor_pi_params], \n",
        "                          {self.state: s, self.act: a, self.adv: adv})\n",
        "        for _ in range(C_EPOCH): # train critic\n",
        "            # update critic\n",
        "            self.sess.run(self.ctrain_op, {self.state: s, self.discounted_r: r})\n",
        "            self.sess.run([self.push_critic_params, \n",
        "                           self.pull_critic_params], \n",
        "                          {self.state: s, self.discounted_r: r})        \n",
        "\n",
        "    def _build_anet(self, scope, name, env, trainable):\n",
        "        with tf.variable_scope(name):\n",
        "            h1 = tf.layers.dense(self.state, hidden, tf.nn.relu, name='hidden', trainable=trainable)\n",
        "            mu = self.env.action_space.high * tf.layers.dense(h1, A_DIM, tf.nn.tanh, name='mu', trainable=trainable)\n",
        "            sigma = tf.layers.dense(h1, A_DIM, tf.nn.softplus, name='sigma', trainable=trainable)\n",
        "            norm_dist = tf.distributions.Normal(loc=mu, scale=sigma)\n",
        "        params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope + '/' + name)\n",
        "        return norm_dist, params\n",
        "\n",
        "    def choose_action(self, s):\n",
        "        s = s[None, :]\n",
        "        a = self.sess.run(self.sample_op, {self.state: s})[0]\n",
        "        return np.clip(a, self.env.action_space.low, self.env.action_space.high)\n",
        "\n",
        "    def get_val(self, s):\n",
        "        if s.ndim < 2: s = s[None, :]\n",
        "        return self.sess.run(self.val, {self.state: s})[0, 0]\n",
        "      \n",
        "    # This function is adapted from OpenAI's Baseline\n",
        "    # GAE computation\n",
        "    # returns TD lamda return & advantage\n",
        "    def add_vtarg_and_adv(self, R, done, V, v_s_, gamma, lam):\n",
        "        # Compute target value using TD(lambda) estimator, and advantage with GAE(lambda)\n",
        "        # last element is only used for last vtarg, but we already zeroed it if last new = 1\n",
        "        done = np.append(done, 0)\n",
        "        V_plus = np.append(V, v_s_)\n",
        "        T = len(R)\n",
        "        adv = gaelam = np.empty(T, 'float32')\n",
        "        lastgaelam = 0\n",
        "        for t in reversed(range(T)):\n",
        "            nonterminal = 1-done[t+1]        \n",
        "            delta = R[t] + gamma * V_plus[t+1] * nonterminal - V_plus[t]\n",
        "            gaelam[t] = lastgaelam = delta + gamma * lam * nonterminal * lastgaelam   \n",
        "        #print(\"adv=\", adv.shape)\n",
        "        #print(\"V=\", V.shape)\n",
        "        #print(\"V_plus=\", V_plus.shape)\n",
        "        tdlamret = np.vstack(adv) + V\n",
        "        #print(\"tdlamret=\", tdlamret.shape)\n",
        "        return tdlamret, adv # tdlamret is critic_target or Qs             "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxjjcOq-ih4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Worker(object):\n",
        "    def __init__(self, wid, GLOBAL_PPO, GLOBAL_EP, GLOBAL_RUNNING_R, sess):\n",
        "        self.wid = wid\n",
        "        self.env = gym.make(GAME).unwrapped\n",
        "        self.g_ppo = GLOBAL_PPO\n",
        "        self.ppo = PPO(wid, sess, self.env, GLOBAL_PPO)\n",
        "        self.running_stats_r = RunningStats()\n",
        "        self.sess = sess\n",
        "        self.GLOBAL_EP = GLOBAL_EP\n",
        "        self.GLOBAL_RUNNING_R = GLOBAL_RUNNING_R        \n",
        "\n",
        "    def work(self):\n",
        "        T = 0\n",
        "        t = 0\n",
        "        SESS = self.sess\n",
        "        GLOBAL_EP = self.GLOBAL_EP\n",
        "        GLOBAL_RUNNING_R = self.GLOBAL_RUNNING_R\n",
        "        \n",
        "        while SESS.run(GLOBAL_EP) < EP_MAX:\n",
        "            s = self.env.reset()\n",
        "            buffer_s, buffer_a, buffer_r, buffer_done, buffer_V = [], [], [], [], []\n",
        "            ep_r = 0\n",
        "            for t in range(EP_LEN):    \n",
        "                a = self.ppo.choose_action(s)\n",
        "                s_, r, done, _ = self.env.step(a)\n",
        "                buffer_s.append(s)\n",
        "                buffer_a.append(a)\n",
        "                buffer_r.append(r)    \n",
        "                buffer_done.append(done)  \n",
        "        \n",
        "                v = self.ppo.get_val(s)\n",
        "                buffer_V.append(v)  \n",
        "        \n",
        "                s = s_\n",
        "                ep_r += r\n",
        "\n",
        "                # update ppo\n",
        "                if (t+1) % BATCH == 0 or t == EP_LEN-1:\n",
        "            \n",
        "                    self.running_stats_r.update(np.array(buffer_r))\n",
        "                    buffer_r = np.clip( (np.array(buffer_r) - self.running_stats_r.mean) / self.running_stats_r.std, -stats_CLIP, stats_CLIP )\n",
        "            \n",
        "                    v_s_ = self.ppo.get_val(s_)                     \n",
        "            \n",
        "                    tdlamret, adv = self.ppo.add_vtarg_and_adv(np.vstack(buffer_r), np.vstack(buffer_done), np.vstack(buffer_V), v_s_, GAMMA, lamda)\n",
        "                        \n",
        "                    bs, ba, br, b_adv = np.vstack(buffer_s), np.vstack(buffer_a), tdlamret, np.vstack(adv)\n",
        "                    buffer_s, buffer_a, buffer_r, buffer_done, buffer_V = [], [], [], [], []\n",
        "            \n",
        "                    self.ppo.update(bs, ba, br, b_adv)            \n",
        "            \n",
        "            SESS.run(GLOBAL_EP.assign_add(1.0))                        \n",
        "            qe = GLOBAL_RUNNING_R.enqueue(ep_r)\n",
        "            SESS.run(qe) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Abb2EkuxizIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GAME = 'Pendulum-v0'\n",
        "env = gym.make(GAME).unwrapped\n",
        "net_scope = 'global'\n",
        "\n",
        "EP_MAX = 500 #500 # max number of episodes\n",
        "EP_LEN = 200 # episode length\n",
        "GAMMA = 0.9\n",
        "\n",
        "lamda = 0.95 #0.95\n",
        "\n",
        "hidden = 50 #100\n",
        "\n",
        "A_LR = 0.0001 # actor's learning rate\n",
        "C_LR = 0.0002 # critic's learning rate\n",
        "BATCH = 32 # minibatch size\n",
        "A_EPOCH = 10 # number of epoch\n",
        "C_EPOCH = 10 # number of epoch\n",
        "S_DIM, A_DIM = 3, 1 # state, action dimension\n",
        "stats_CLIP = 10 # upper bound of RunningStats\n",
        "epsilon=0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRWC1gf2jlFQ",
        "colab_type": "code",
        "outputId": "0a1cf42d-8ff9-41b7-8da6-845d0a1b6c93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2122
        }
      },
      "source": [
        "cluster = tf.train.ClusterSpec({\n",
        "    \"worker\": [\"localhost:3331\",\n",
        "               \"localhost:3332\",\n",
        "               \"localhost:3333\",\n",
        "               \"localhost:3334\"\n",
        "              ],\n",
        "    \"ps\": [\"localhost:3330\"]\n",
        "})\n",
        "\n",
        "def parameter_server():\n",
        "    #tf.reset_default_graph()\n",
        "    \n",
        "    server = tf.train.Server(cluster,\n",
        "                             job_name=\"ps\",\n",
        "                             task_index=0)\n",
        "    sess = tf.Session(target=server.target)        \n",
        "    \n",
        "    with tf.device(\"/job:ps/task:0\"):\n",
        "        GLOBAL_PPO = PPO(net_scope, sess, env, global_PPO=None) # only need its params\n",
        "        GLOBAL_EP = tf.Variable(0.0, name='GLOBAL_EP') # num of global episodes   \n",
        "        # a queue of ep_r\n",
        "        GLOBAL_RUNNING_R = tf.FIFOQueue(EP_MAX, tf.float32, shared_name=\"GLOBAL_RUNNING_R\")        \n",
        "    \n",
        "    print(\"Parameter server: waiting for cluster connection...\")\n",
        "    sess.run(tf.report_uninitialized_variables())\n",
        "    print(\"Parameter server: cluster ready!\")\n",
        "    \n",
        "    print(\"Parameter server: initializing variables...\")\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    print(\"Parameter server: variables initialized\")\n",
        "    \n",
        "    while True:\n",
        "        time.sleep(1.0)\n",
        "        if sess.run(GLOBAL_RUNNING_R.size()) >= EP_MAX: # GLOBAL_EP starts from 0, hence +1 to max_global_episodes          \n",
        "            time.sleep(10.0)\n",
        "            GLOBAL_RUNNING_R_list = []\n",
        "            ep_r_prev = 0.0\n",
        "            for i in range(sess.run(GLOBAL_RUNNING_R.size())):\n",
        "                ep_r = sess.run(GLOBAL_RUNNING_R.dequeue())                   \n",
        "                if i==0:\n",
        "                    GLOBAL_RUNNING_R_list.append(ep_r) # for display\n",
        "                else:\n",
        "                    GLOBAL_RUNNING_R_list.append(GLOBAL_RUNNING_R_list[-1]*0.9 + ep_r*0.1) # for display         \n",
        "            break  \n",
        "              \n",
        "    # display\n",
        "    plt.plot(np.arange(len(GLOBAL_RUNNING_R_list)), GLOBAL_RUNNING_R_list)\n",
        "    plt.xlabel('episode')\n",
        "    plt.ylabel('reward')\n",
        "    plt.show()  \n",
        "\n",
        "    #print(\"Parameter server: blocking...\")\n",
        "    #server.join() # currently blocks forever    \n",
        "    print(\"Parameter server: ended...\")\n",
        "\n",
        "def worker(worker_n): \n",
        "    #tf.reset_default_graph()\n",
        "    \n",
        "    server = tf.train.Server(cluster,\n",
        "                             job_name=\"worker\",\n",
        "                             task_index=worker_n)\n",
        "    sess = tf.Session(target=server.target)  \n",
        "  \n",
        "    with tf.device(\"/job:ps/task:0\"):\n",
        "        GLOBAL_PPO = PPO(net_scope, sess, env, global_PPO=None) # only need its params\n",
        "        GLOBAL_EP = tf.Variable(0.0, name='GLOBAL_EP') # num of global episodes\n",
        "        # a queue of ep_r\n",
        "        GLOBAL_RUNNING_R = tf.FIFOQueue(EP_MAX, tf.float32, shared_name=\"GLOBAL_RUNNING_R\")   \n",
        "    \"\"\"\n",
        "    with tf.device(tf.train.replica_device_setter(\n",
        "                        worker_device='/job:worker/task:' + str(worker_n),\n",
        "                        cluster=cluster)):\n",
        "    \"\"\"                        \n",
        "    print(\"Worker %d: waiting for cluster connection...\" % worker_n)\n",
        "    sess.run(tf.report_uninitialized_variables())\n",
        "    print(\"Worker %d: cluster ready!\" % worker_n)\n",
        "    \n",
        "    #while sess.run(tf.report_uninitialized_variables()):\n",
        "    while (sess.run(tf.report_uninitialized_variables())).any(): # ********** .any() .all() **********\n",
        "        print(\"Worker %d: waiting for variable initialization...\" % worker_n)\n",
        "        time.sleep(1.0)\n",
        "    print(\"Worker %d: variables initialized\" % worker_n)\n",
        "    \n",
        "    w = Worker(str(worker_n), GLOBAL_PPO, GLOBAL_EP, GLOBAL_RUNNING_R, sess) \n",
        "    print(\"Worker %d: created\" % worker_n)\n",
        "    \n",
        "    sess.run(tf.global_variables_initializer()) # got to initialize after Worker creation\n",
        "    w.work()\n",
        "    print(\"Worker %d: w.work()\" % worker_n)\n",
        "          \n",
        "    #print(\"Worker %d: blocking...\" % worker_n)\n",
        "    server.join() # currently blocks forever\n",
        "    print(\"Worker %d: ended...\" % worker_n)\n",
        "    \n",
        "start_time = time.time()\n",
        "\n",
        "ps_proc = Process(target=parameter_server, daemon=True)\n",
        "w1_proc = Process(target=worker, args=(0, ), daemon=True)\n",
        "w2_proc = Process(target=worker, args=(1, ), daemon=True)\n",
        "w3_proc = Process(target=worker, args=(2, ), daemon=True)\n",
        "w4_proc = Process(target=worker, args=(3, ), daemon=True)\n",
        "\n",
        "ps_proc.start()\n",
        "w1_proc.start()\n",
        "w2_proc.start()\n",
        "w3_proc.start()\n",
        "w4_proc.start() \n",
        "\n",
        "# if not join, parent will terminate before children \n",
        "# & children will terminate as well cuz children are daemon\n",
        "ps_proc.join() \n",
        "#w1_proc.join()\n",
        "#w2_proc.join() \n",
        "#w3_proc.join() \n",
        "#w4_proc.join() \n",
        "\n",
        "for proc in [w1_proc, \n",
        "             w2_proc, \n",
        "             w3_proc, \n",
        "             w4_proc, \n",
        "             ps_proc]:\n",
        "    proc.terminate() # only way to kill server is to kill it's process\n",
        "        \n",
        "print('All done.')     \n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0624 10:08:48.052905 139882947254144 deprecation.py:323] From <ipython-input-4-721e1883fe74>:15: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "W0624 10:08:48.166731 139882947254144 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.WARNING: Logging before flag parsing goes to stderr.\n",
            "\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0624 10:08:48.168701 139882947254144 deprecation.py:323] From <ipython-input-4-721e1883fe74>:15: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "W0624 10:08:48.158434 139882947254144 deprecation.py:323] From <ipython-input-4-721e1883fe74>:15: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "W0624 10:08:48.223961 139882947254144 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.WARNING: Logging before flag parsing goes to stderr.\n",
            "W0624 10:08:48.228845 139882947254144 deprecation.py:323] From <ipython-input-4-721e1883fe74>:15: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "\n",
            "W0624 10:08:48.265631 139882947254144 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.W0624 10:08:48.241619 139882947254144 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0624 10:08:48.296985 139882947254144 deprecation.py:323] From <ipython-input-4-721e1883fe74>:15: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "W0624 10:08:48.369096 139882947254144 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0624 10:08:48.960546 139882947254144 deprecation.py:323] From <ipython-input-4-721e1883fe74>:74: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
            "W0624 10:08:48.983800 139882947254144 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
            "W0624 10:08:49.012147 139882947254144 deprecation.py:323] From <ipython-input-4-721e1883fe74>:74: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
            "W0624 10:08:49.038850 139882947254144 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
            "W0624 10:08:49.163636 139882947254144 deprecation.py:323] From <ipython-input-4-721e1883fe74>:74: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
            "W0624 10:08:49.192498 139882947254144 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
            "W0624 10:08:49.227377 139882947254144 deprecation.py:323] From <ipython-input-4-721e1883fe74>:74: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.W0624 10:08:49.244177 139882947254144 deprecation.py:323] From <ipython-input-4-721e1883fe74>:74: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
            "\n",
            "W0624 10:08:49.263926 139882947254144 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.W0624 10:08:49.272351 139882947254144 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
            "\n",
            "W0624 10:08:50.006113 139882947254144 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1251: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0624 10:08:50.145243 139882947254144 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1251: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0624 10:08:50.243255 139882947254144 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1251: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0624 10:08:50.340315 139882947254144 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1251: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0624 10:08:50.558332 139882947254144 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1251: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Worker 2: waiting for cluster connection...\n",
            "Parameter server: waiting for cluster connection...\n",
            "Worker 3: waiting for cluster connection...\n",
            "Worker 1: waiting for cluster connection...\n",
            "Worker 2: cluster ready!\n",
            "Worker 3: cluster ready!\n",
            "Worker 0: waiting for cluster connection...\n",
            "Parameter server: cluster ready!\n",
            "Parameter server: initializing variables...\n",
            "Worker 1: cluster ready!\n",
            "Parameter server: variables initialized\n",
            "Worker 3: variables initialized\n",
            "Worker 2: variables initialized\n",
            "Worker 0: cluster ready!\n",
            "Worker 1: variables initialized\n",
            "Worker 0: variables initialized\n",
            "Worker 3: created\n",
            "Worker 1: created\n",
            "Worker 2: created\n",
            "Worker 0: created\n",
            "Worker 2: w.work()\n",
            "Worker 1: w.work()\n",
            "Worker 0: w.work()\n",
            "Worker 3: w.work()\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEKCAYAAADenhiQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfqfBRSmllN/9f8nUOaZkIDYAAAABSURBVFPaWn2mAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Parameter server: ended...\n",
            "All done.\n",
            "--- 602.1372051239014 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}