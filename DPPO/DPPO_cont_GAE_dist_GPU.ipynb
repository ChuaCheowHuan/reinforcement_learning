{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DPPO_cont_GAE_dist_GPU.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avhpCbbd3563",
        "colab_type": "text"
      },
      "source": [
        "Distributed Proximal Policy Optimization (Distributed PPO or DPPO)  implementation with distributed Tensorflow and Python’s multiprocessing \n",
        "package. This implementation uses normalized running rewards with GAE. The code \n",
        "is tested with Gym’s Pendulum-v0 (continuous action space) on Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyShhxiM3_3L",
        "colab_type": "text"
      },
      "source": [
        "#Use tensorflow version 1.15.2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udIdxLu04DxQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "fd86c702-1d68-443c-c8f2-d22c7e915d26"
      },
      "source": [
        "!pip install tensorflow==1.15.2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.15.2 in /usr/local/lib/python3.6/dist-packages (1.15.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.28.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.18.3)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (3.2.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.12.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.34.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (3.10.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.2.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.9.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.15.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (46.1.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.2) (2.10.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-fqmZuy3-jW",
        "colab_type": "text"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93E4LcmdiYsV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "#!pip install -q tf-nightly\n",
        "\n",
        "import gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "tf.reset_default_graph()\n",
        "\n",
        "import time\n",
        "from multiprocessing import Process"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53XNjXLH4ZEP",
        "colab_type": "text"
      },
      "source": [
        "#Computes running stats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFfwwCjNibWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The following class is adapted from OpenAI's baseline:\n",
        "# https://github.com/openai/baselines/blob/master/baselines/common/running_mean_std.py\n",
        "# https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Parallel_algorithm\n",
        "# This class is used for the normalization of rewards in this program before GAE computation.\n",
        "class RunningStats(object):\n",
        "    def __init__(self, epsilon=1e-4, shape=()):\n",
        "        self.mean = np.zeros(shape, 'float64')\n",
        "        self.var = np.ones(shape, 'float64')\n",
        "        self.std = np.ones(shape, 'float64')\n",
        "        self.count = epsilon\n",
        "\n",
        "    def update(self, x):\n",
        "        batch_mean = np.mean(x, axis=0)\n",
        "        batch_var = np.var(x, axis=0)\n",
        "        batch_count = x.shape[0]\n",
        "        self.update_from_moments(batch_mean, batch_var, batch_count)\n",
        "\n",
        "    def update_from_moments(self, batch_mean, batch_var, batch_count):\n",
        "        delta = batch_mean - self.mean\n",
        "        new_mean = self.mean + delta * batch_count / (self.count + batch_count)\n",
        "        m_a = self.var * self.count\n",
        "        m_b = batch_var * batch_count\n",
        "        M2 = m_a + m_b + np.square(delta) * self.count * batch_count / (self.count + batch_count)\n",
        "        new_var = M2 / (self.count + batch_count)\n",
        "\n",
        "        self.mean = new_mean\n",
        "        self.var = new_var\n",
        "        self.std = np.maximum(np.sqrt(self.var), 1e-6)\n",
        "        self.count = batch_count + self.count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9C5g2it34dS_",
        "colab_type": "text"
      },
      "source": [
        "#PPO tensorflow graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNuMXS_T2QkB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PPO(object):    \n",
        "    def __init__(self, scope, sess, env, global_PPO=None):    \n",
        "        self.sess = sess\n",
        "        self.env = env\n",
        "        #OPT_A = tf.train.AdamOptimizer(A_LR, beta1=0.99, beta2=0.999, name='OPT_A')\n",
        "        #OPT_C = tf.train.AdamOptimizer(C_LR, beta1=0.99, beta2=0.999, name='OPT_C')          \n",
        "        OPT_A = tf.train.AdamOptimizer(A_LR, name='OPT_A')\n",
        "        OPT_C = tf.train.AdamOptimizer(C_LR, name='OPT_C')          \n",
        "        \n",
        "        with tf.variable_scope(scope): # scope is either global or wid\n",
        "            self.state = tf.placeholder(tf.float32, [None, S_DIM], 'state')\n",
        "\n",
        "            # critic\n",
        "            with tf.variable_scope('critic'):\n",
        "                h1 = tf.layers.dense(self.state, hidden, tf.nn.relu, name='hidden', trainable=True)\n",
        "                self.val = tf.layers.dense(h1, 1, name='val', trainable=True)                \n",
        "                self.critic_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope + '/critic')\n",
        "                self.discounted_r = tf.placeholder(tf.float32, [None, 1], 'discounted_r')\n",
        "                self.advantage = self.discounted_r - self.val\n",
        "                self.closs = tf.reduce_mean(tf.square(self.advantage))\n",
        "                self.ctrain_op = OPT_C.minimize(self.closs)\n",
        "            with tf.variable_scope('cgrads'):\n",
        "                self.critic_grad_op = tf.gradients(self.closs, self.critic_params)\n",
        "\n",
        "            # actor\n",
        "            self.pi, self.pi_params = self._build_anet(scope, 'pi', self.env, trainable=True)\n",
        "            self.oldpi, self.oldpi_params = self._build_anet(scope, 'oldpi', self.env, trainable=True)  # originally trainable=False\n",
        "            with tf.variable_scope('sample_action'):\n",
        "                self.sample_op = tf.squeeze(self.pi.sample(1), axis=0) # choosing action\n",
        "            with tf.variable_scope('update_oldpi'):\n",
        "                self.update_oldpi_op = [oldp.assign(p) for p, oldp in zip(self.pi_params, self.oldpi_params)]\n",
        "            self.act = tf.placeholder(tf.float32, [None, A_DIM], 'action')\n",
        "            self.adv = tf.placeholder(tf.float32, [None, 1], 'advantage')\n",
        "            with tf.variable_scope('loss'):\n",
        "                with tf.variable_scope('surrogate'):\n",
        "                    ratio = self.pi.prob(self.act) / self.oldpi.prob(self.act)\n",
        "                    surr = ratio * self.adv\n",
        "                    self.aloss = -tf.reduce_mean(tf.minimum(surr, tf.clip_by_value(ratio, 1.-epsilon, 1.+epsilon)*self.adv))\n",
        "            with tf.variable_scope('atrain'):\n",
        "                self.atrain_op = OPT_A.minimize(self.aloss)\n",
        "            with tf.variable_scope('agrads'):\n",
        "                self.pi_grad_op = tf.gradients(self.aloss, self.pi_params)\n",
        "                \n",
        "            if scope != net_scope: # not global    \n",
        "                with tf.name_scope('params'): # push/pull from local/worker perspective\n",
        "                    with tf.name_scope('push_to_global'):\n",
        "                        self.push_actor_pi_params = OPT_A.apply_gradients(zip(self.pi_grad_op, global_PPO.pi_params))\n",
        "                        self.push_critic_params = OPT_C.apply_gradients(zip(self.critic_grad_op, global_PPO.critic_params))\n",
        "                    with tf.name_scope('pull_fr_global'):\n",
        "                        self.pull_actor_pi_params = [local_params.assign(global_params) for local_params, global_params in zip(self.pi_params, global_PPO.pi_params)]\n",
        "                        self.pull_critic_params = [local_params.assign(global_params) for local_params, global_params in zip(self.critic_params, global_PPO.critic_params)]                    \n",
        "                \n",
        "    def update(self, s, a, r, adv):\n",
        "        self.sess.run(self.update_oldpi_op)\n",
        "\n",
        "        for _ in range(A_EPOCH): # train actor\n",
        "            self.sess.run(self.atrain_op, {self.state: s, self.act: a, self.adv: adv})\n",
        "            # update actor\n",
        "            self.sess.run([self.push_actor_pi_params, \n",
        "                           self.pull_actor_pi_params], \n",
        "                          {self.state: s, self.act: a, self.adv: adv})\n",
        "        for _ in range(C_EPOCH): # train critic\n",
        "            # update critic\n",
        "            self.sess.run(self.ctrain_op, {self.state: s, self.discounted_r: r})\n",
        "            self.sess.run([self.push_critic_params, \n",
        "                           self.pull_critic_params], \n",
        "                          {self.state: s, self.discounted_r: r})        \n",
        "\n",
        "    def _build_anet(self, scope, name, env, trainable):\n",
        "        with tf.variable_scope(name):\n",
        "            h1 = tf.layers.dense(self.state, hidden, tf.nn.relu, name='hidden', trainable=trainable)\n",
        "            mu = self.env.action_space.high * tf.layers.dense(h1, A_DIM, tf.nn.tanh, name='mu', trainable=trainable)\n",
        "            sigma = tf.layers.dense(h1, A_DIM, tf.nn.softplus, name='sigma', trainable=trainable)\n",
        "            norm_dist = tf.distributions.Normal(loc=mu, scale=sigma)\n",
        "        params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope + '/' + name)\n",
        "        return norm_dist, params\n",
        "\n",
        "    def choose_action(self, s):\n",
        "        s = s[None, :]\n",
        "        a = self.sess.run(self.sample_op, {self.state: s})[0]\n",
        "        return np.clip(a, self.env.action_space.low, self.env.action_space.high)\n",
        "\n",
        "    def get_val(self, s):\n",
        "        if s.ndim < 2: s = s[None, :]\n",
        "        return self.sess.run(self.val, {self.state: s})[0, 0]\n",
        "      \n",
        "    # This function is adapted from OpenAI's Baseline\n",
        "    # GAE computation\n",
        "    # returns TD lamda return & advantage\n",
        "    def add_vtarg_and_adv(self, R, done, V, v_s_, gamma, lam):\n",
        "        # Compute target value using TD(lambda) estimator, and advantage with GAE(lambda)\n",
        "        # last element is only used for last vtarg, but we already zeroed it if last new = 1\n",
        "        done = np.append(done, 0)\n",
        "        V_plus = np.append(V, v_s_)\n",
        "        T = len(R)\n",
        "        adv = gaelam = np.empty(T, 'float32')\n",
        "        lastgaelam = 0\n",
        "        for t in reversed(range(T)):\n",
        "            nonterminal = 1-done[t+1]        \n",
        "            delta = R[t] + gamma * V_plus[t+1] * nonterminal - V_plus[t]\n",
        "            gaelam[t] = lastgaelam = delta + gamma * lam * nonterminal * lastgaelam   \n",
        "        #print(\"adv=\", adv.shape)\n",
        "        #print(\"V=\", V.shape)\n",
        "        #print(\"V_plus=\", V_plus.shape)\n",
        "        tdlamret = np.vstack(adv) + V\n",
        "        #print(\"tdlamret=\", tdlamret.shape)\n",
        "        return tdlamret, adv # tdlamret is critic_target or Qs             "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ImZ0y974hwf",
        "colab_type": "text"
      },
      "source": [
        "#The worker class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxjjcOq-ih4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Worker(object):\n",
        "    def __init__(self, wid, GLOBAL_PPO, GLOBAL_EP, GLOBAL_RUNNING_R, sess):\n",
        "        self.wid = wid\n",
        "        self.env = gym.make(GAME).unwrapped\n",
        "        self.g_ppo = GLOBAL_PPO\n",
        "        self.ppo = PPO(wid, sess, self.env, GLOBAL_PPO)\n",
        "        self.running_stats_r = RunningStats()\n",
        "        self.sess = sess\n",
        "        self.GLOBAL_EP = GLOBAL_EP\n",
        "        self.GLOBAL_RUNNING_R = GLOBAL_RUNNING_R        \n",
        "\n",
        "    def work(self):\n",
        "        T = 0\n",
        "        t = 0\n",
        "        SESS = self.sess\n",
        "        GLOBAL_EP = self.GLOBAL_EP\n",
        "        GLOBAL_RUNNING_R = self.GLOBAL_RUNNING_R\n",
        "        \n",
        "        while SESS.run(GLOBAL_EP) < EP_MAX:\n",
        "            s = self.env.reset()\n",
        "            buffer_s, buffer_a, buffer_r, buffer_done, buffer_V = [], [], [], [], []\n",
        "            ep_r = 0\n",
        "            for t in range(EP_LEN):    \n",
        "                a = self.ppo.choose_action(s)\n",
        "                s_, r, done, _ = self.env.step(a)\n",
        "                buffer_s.append(s)\n",
        "                buffer_a.append(a)\n",
        "                buffer_r.append(r)    \n",
        "                buffer_done.append(done)  \n",
        "        \n",
        "                v = self.ppo.get_val(s)\n",
        "                buffer_V.append(v)  \n",
        "        \n",
        "                s = s_\n",
        "                ep_r += r\n",
        "\n",
        "                # update ppo\n",
        "                if (t+1) % BATCH == 0 or t == EP_LEN-1:\n",
        "            \n",
        "                    self.running_stats_r.update(np.array(buffer_r))\n",
        "                    buffer_r = np.clip( (np.array(buffer_r) - self.running_stats_r.mean) / self.running_stats_r.std, -stats_CLIP, stats_CLIP )\n",
        "            \n",
        "                    v_s_ = self.ppo.get_val(s_)                     \n",
        "            \n",
        "                    tdlamret, adv = self.ppo.add_vtarg_and_adv(np.vstack(buffer_r), np.vstack(buffer_done), np.vstack(buffer_V), v_s_, GAMMA, lamda)\n",
        "                        \n",
        "                    bs, ba, br, b_adv = np.vstack(buffer_s), np.vstack(buffer_a), tdlamret, np.vstack(adv)\n",
        "                    buffer_s, buffer_a, buffer_r, buffer_done, buffer_V = [], [], [], [], []\n",
        "            \n",
        "                    self.ppo.update(bs, ba, br, b_adv)            \n",
        "            \n",
        "            SESS.run(GLOBAL_EP.assign_add(1.0))                        \n",
        "            qe = GLOBAL_RUNNING_R.enqueue(ep_r)\n",
        "            SESS.run(qe) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blnJIJAE4ks4",
        "colab_type": "text"
      },
      "source": [
        "#Global variables & hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Abb2EkuxizIZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2022dfca-c4e8-475e-dd1d-b0ed09b92846"
      },
      "source": [
        "GAME = 'Pendulum-v0'\n",
        "env = gym.make(GAME).unwrapped\n",
        "net_scope = 'global'\n",
        "\n",
        "EP_MAX = 500 #500 # max number of episodes\n",
        "EP_LEN = 200 # episode length\n",
        "GAMMA = 0.9\n",
        "\n",
        "lamda = 0.95 #0.95\n",
        "\n",
        "hidden = 50 #100\n",
        "\n",
        "A_LR = 0.0001 # actor's learning rate\n",
        "C_LR = 0.0002 # critic's learning rate\n",
        "BATCH = 32 # minibatch size\n",
        "A_EPOCH = 10 # number of epoch\n",
        "C_EPOCH = 10 # number of epoch\n",
        "S_DIM, A_DIM = 3, 1 # state, action dimension\n",
        "stats_CLIP = 10 # upper bound of RunningStats\n",
        "epsilon=0.2"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpNtcG8S4r8i",
        "colab_type": "text"
      },
      "source": [
        "#Setup cluster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRWC1gf2jlFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cluster = tf.train.ClusterSpec({\n",
        "    \"worker\": [\"localhost:3331\",\n",
        "               \"localhost:3332\",\n",
        "               \"localhost:3333\",\n",
        "               \"localhost:3334\"\n",
        "              ],\n",
        "    \"ps\": [\"localhost:3330\"]\n",
        "})\n",
        "\n",
        "def parameter_server():\n",
        "    #tf.reset_default_graph()\n",
        "    \n",
        "    server = tf.train.Server(cluster,\n",
        "                             job_name=\"ps\",\n",
        "                             task_index=0)\n",
        "    sess = tf.Session(target=server.target)        \n",
        "    \n",
        "    with tf.device(\"/job:ps/task:0\"):\n",
        "        GLOBAL_PPO = PPO(net_scope, sess, env, global_PPO=None) # only need its params\n",
        "        GLOBAL_EP = tf.Variable(0.0, name='GLOBAL_EP') # num of global episodes   \n",
        "        # a queue of ep_r\n",
        "        GLOBAL_RUNNING_R = tf.FIFOQueue(EP_MAX, tf.float32, shared_name=\"GLOBAL_RUNNING_R\")        \n",
        "    \n",
        "    print(\"Parameter server: waiting for cluster connection...\")\n",
        "    sess.run(tf.report_uninitialized_variables())\n",
        "    print(\"Parameter server: cluster ready!\")\n",
        "    \n",
        "    print(\"Parameter server: initializing variables...\")\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    print(\"Parameter server: variables initialized\")\n",
        "    \n",
        "    while True:\n",
        "        time.sleep(1.0)\n",
        "        if sess.run(GLOBAL_RUNNING_R.size()) >= EP_MAX: # GLOBAL_EP starts from 0, hence +1 to max_global_episodes          \n",
        "            time.sleep(10.0)\n",
        "            GLOBAL_RUNNING_R_list = []\n",
        "            ep_r_prev = 0.0\n",
        "            for i in range(sess.run(GLOBAL_RUNNING_R.size())):\n",
        "                ep_r = sess.run(GLOBAL_RUNNING_R.dequeue())                   \n",
        "                if i==0:\n",
        "                    GLOBAL_RUNNING_R_list.append(ep_r) # for display\n",
        "                else:\n",
        "                    GLOBAL_RUNNING_R_list.append(GLOBAL_RUNNING_R_list[-1]*0.9 + ep_r*0.1) # for display         \n",
        "            break  \n",
        "              \n",
        "    # display\n",
        "    plt.plot(np.arange(len(GLOBAL_RUNNING_R_list)), GLOBAL_RUNNING_R_list)\n",
        "    plt.xlabel('episode')\n",
        "    plt.ylabel('reward')\n",
        "    plt.show()  \n",
        "\n",
        "    #print(\"Parameter server: blocking...\")\n",
        "    #server.join() # currently blocks forever    \n",
        "    print(\"Parameter server: ended...\")\n",
        "\n",
        "def worker(worker_n): \n",
        "    #tf.reset_default_graph()\n",
        "    \n",
        "    server = tf.train.Server(cluster,\n",
        "                             job_name=\"worker\",\n",
        "                             task_index=worker_n)\n",
        "    sess = tf.Session(target=server.target)  \n",
        "  \n",
        "    with tf.device(\"/job:ps/task:0\"):\n",
        "        GLOBAL_PPO = PPO(net_scope, sess, env, global_PPO=None) # only need its params\n",
        "        GLOBAL_EP = tf.Variable(0.0, name='GLOBAL_EP') # num of global episodes\n",
        "        # a queue of ep_r\n",
        "        GLOBAL_RUNNING_R = tf.FIFOQueue(EP_MAX, tf.float32, shared_name=\"GLOBAL_RUNNING_R\")   \n",
        "    \"\"\"\n",
        "    with tf.device(tf.train.replica_device_setter(\n",
        "                        worker_device='/job:worker/task:' + str(worker_n),\n",
        "                        cluster=cluster)):\n",
        "    \"\"\"                        \n",
        "    print(\"Worker %d: waiting for cluster connection...\" % worker_n)\n",
        "    sess.run(tf.report_uninitialized_variables())\n",
        "    print(\"Worker %d: cluster ready!\" % worker_n)\n",
        "    \n",
        "    #while sess.run(tf.report_uninitialized_variables()):\n",
        "    while (sess.run(tf.report_uninitialized_variables())).any(): # ********** .any() .all() **********\n",
        "        print(\"Worker %d: waiting for variable initialization...\" % worker_n)\n",
        "        time.sleep(1.0)\n",
        "    print(\"Worker %d: variables initialized\" % worker_n)\n",
        "    \n",
        "    w = Worker(str(worker_n), GLOBAL_PPO, GLOBAL_EP, GLOBAL_RUNNING_R, sess) \n",
        "    print(\"Worker %d: created\" % worker_n)\n",
        "    \n",
        "    sess.run(tf.global_variables_initializer()) # got to initialize after Worker creation\n",
        "    w.work()\n",
        "    print(\"Worker %d: w.work()\" % worker_n)\n",
        "          \n",
        "    #print(\"Worker %d: blocking...\" % worker_n)\n",
        "    server.join() # currently blocks forever\n",
        "    print(\"Worker %d: ended...\" % worker_n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEio_lxF4zSj",
        "colab_type": "text"
      },
      "source": [
        "#Setup processes, rollout & train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KSlM79h4yii",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "33b7f0ba-83bc-4cf7-a211-b73da961023e"
      },
      "source": [
        "start_time = time.time()\n",
        "\n",
        "ps_proc = Process(target=parameter_server, daemon=True)\n",
        "w1_proc = Process(target=worker, args=(0, ), daemon=True)\n",
        "w2_proc = Process(target=worker, args=(1, ), daemon=True)\n",
        "w3_proc = Process(target=worker, args=(2, ), daemon=True)\n",
        "w4_proc = Process(target=worker, args=(3, ), daemon=True)\n",
        "\n",
        "ps_proc.start()\n",
        "w1_proc.start()\n",
        "w2_proc.start()\n",
        "w3_proc.start()\n",
        "w4_proc.start() \n",
        "\n",
        "# if not join, parent will terminate before children \n",
        "# & children will terminate as well cuz children are daemon\n",
        "ps_proc.join() \n",
        "#w1_proc.join()\n",
        "#w2_proc.join() \n",
        "#w3_proc.join() \n",
        "#w4_proc.join() \n",
        "\n",
        "for proc in [w1_proc, \n",
        "             w2_proc, \n",
        "             w3_proc, \n",
        "             w4_proc, \n",
        "             ps_proc]:\n",
        "    proc.terminate() # only way to kill server is to kill it's process\n",
        "        \n",
        "print('All done.')     \n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))    "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-4-721e1883fe74>:15: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From <ipython-input-4-721e1883fe74>:15: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-4-721e1883fe74>:15: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.WARNING:tensorflow:From <ipython-input-4-721e1883fe74>:15: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-4-721e1883fe74>:15: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From <ipython-input-4-721e1883fe74>:74: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
            "WARNING:tensorflow:From <ipython-input-4-721e1883fe74>:74: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
            "WARNING:tensorflow:From <ipython-input-4-721e1883fe74>:74: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
            "WARNING:tensorflow:From <ipython-input-4-721e1883fe74>:74: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.WARNING:tensorflow:From <ipython-input-4-721e1883fe74>:74: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
            "\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.whereWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "\n",
            "Worker 2: waiting for cluster connection...\n",
            "Worker 1: waiting for cluster connection...\n",
            "Worker 0: waiting for cluster connection...\n",
            "Parameter server: waiting for cluster connection...\n",
            "Worker 3: waiting for cluster connection...\n",
            "Worker 2: cluster ready!\n",
            "Worker 0: cluster ready!\n",
            "Worker 1: cluster ready!\n",
            "Worker 3: cluster ready!\n",
            "Parameter server: cluster ready!\n",
            "Parameter server: initializing variables...\n",
            "Worker 2: waiting for variable initialization...\n",
            "Worker 1: waiting for variable initialization...\n",
            "Parameter server: variables initialized\n",
            "Worker 3: variables initialized\n",
            "Worker 0: variables initialized\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
            "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Worker 2: variables initialized\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Worker 1: variables initialized\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Worker 0: created\n",
            "Worker 3: created\n",
            "Worker 2: created\n",
            "Worker 1: created\n",
            "Worker 3: w.work()\n",
            "Worker 1: w.work()\n",
            "Worker 0: w.work()\n",
            "Worker 2: w.work()\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Parameter server: ended...\n",
            "All done.\n",
            "--- 708.0910649299622 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}