{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A3C_disc_max_dist.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lm3QvfmQfm-m",
        "colab_type": "text"
      },
      "source": [
        "A3C (Asynchronous Advantage Actor Critic) implementation with distributed \n",
        "Tensorflow & Python multiprocessing package. This is a discrete version with \n",
        "N-step targets (use maximum terms possible). The code is tested with Gymâ€™s \n",
        "discrete action space environment, CartPole-v0 on Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9zCOia0fzPa",
        "colab_type": "text"
      },
      "source": [
        "#Use tensorflow version 1.15.2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWeVDJ-3fzvf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "5df1dfee-9a9b-4bf9-b0b5-a37414bdd923"
      },
      "source": [
        "!pip install tensorflow==1.15.2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.15.2 in /usr/local/lib/python3.6/dist-packages (1.15.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.18.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.9.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.12.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.34.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (3.10.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.28.1)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.15.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (3.2.1)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.2.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.8.1)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.2.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.0.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15.2) (46.1.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.2) (2.10.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3StxCaIfsDq",
        "colab_type": "text"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkRl7adsfsba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from multiprocessing import Process\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import gym\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mUgm78Cf8VM",
        "colab_type": "text"
      },
      "source": [
        "#The actor-critic tensorflow graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQso0DMQvaZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tf Graph, ops\n",
        "class ACNet(object):\n",
        "    def __init__(self, scope, sess, globalAC=None):\n",
        "        self.sess = sess\n",
        "        OPT_A = tf.train.AdamOptimizer(actor_alpha, beta1=0.99, beta2=0.999, name='OPT_A')\n",
        "        OPT_C = tf.train.AdamOptimizer(critic_alpha, beta1=0.99, beta2=0.999, name='OPT_C')          \n",
        "        \n",
        "        if scope == net_scope: # global\n",
        "            with tf.variable_scope(scope):\n",
        "                self.s = tf.placeholder(tf.float32, [None, num_obvs], 'S')\n",
        "                # create global net\n",
        "                self.actor_params, self.critic_params = self._create_net(scope)[-2:] # only require params\n",
        "                \n",
        "        else: # local\n",
        "            with tf.variable_scope(scope):\n",
        "                self.s = tf.placeholder(tf.float32, [None, num_obvs], 'S')\n",
        "                self.a = tf.placeholder(tf.int32, [None, ], 'A')\n",
        "                self.critic_target = tf.placeholder(tf.float32, [None, 1], 'critic_target')\n",
        "                self.baselined_returns = tf.placeholder(tf.float32, [None, 1], 'baselined_returns') # for calculating advantage \n",
        "                # create local net\n",
        "                self.action_prob, self.V, self.actor_params, self.critic_params = self._create_net(scope)\n",
        "                    \n",
        "                TD_err = tf.subtract(self.critic_target, self.V, name='TD_err')\n",
        "                with tf.name_scope('actor_loss'):\n",
        "                    log_prob = tf.reduce_sum(tf.log(self.action_prob + 1e-5) * tf.one_hot(self.a, num_actions, dtype=tf.float32), axis=1, keep_dims=True)\n",
        "                    actor_component = log_prob * tf.stop_gradient(self.baselined_returns)\n",
        "                    # entropy for exploration\n",
        "                    entropy = -tf.reduce_sum(self.action_prob * tf.log(self.action_prob + 1e-5), axis=1, keep_dims=True)  # encourage exploration\n",
        "                    self.actor_loss = tf.reduce_mean( -(ENTROPY_BETA * entropy + actor_component) )                                        \n",
        "                with tf.name_scope('critic_loss'):\n",
        "                    self.critic_loss = tf.reduce_mean(tf.square(TD_err))                      \n",
        "                # accumulated gradients for local actor    \n",
        "                with tf.name_scope('local_actor_grad'):                   \n",
        "                    self.actor_zero_op, self.actor_accumu_op, self.actor_apply_op, actor_accum = self.accumu_grad(OPT_A, self.actor_loss, scope=scope + '/actor')\n",
        "                # ********** accumulated gradients for local critic **********\n",
        "                with tf.name_scope('local_critic_grad'):\n",
        "                    self.critic_zero_op, self.critic_accumu_op, self.critic_apply_op, critic_accum = self.accumu_grad(OPT_C, self.critic_loss, scope=scope + '/critic')\n",
        "                    \n",
        "            with tf.name_scope('params'): # push/pull from local/worker perspective\n",
        "                with tf.name_scope('push_to_global'):\n",
        "                    self.push_actor_params = OPT_A.apply_gradients(zip(actor_accum, globalAC.actor_params))\n",
        "                    self.push_critic_params = OPT_C.apply_gradients(zip(critic_accum, globalAC.critic_params))\n",
        "                with tf.name_scope('pull_fr_global'):\n",
        "                    self.pull_actor_params = [local_params.assign(global_params) for local_params, global_params in zip(self.actor_params, globalAC.actor_params)]\n",
        "                    self.pull_critic_params = [local_params.assign(global_params) for local_params, global_params in zip(self.critic_params, globalAC.critic_params)]                    \n",
        "                    \n",
        "    def _create_net(self, scope):\n",
        "        w_init = tf.glorot_uniform_initializer()\n",
        "        with tf.variable_scope('actor'):\n",
        "            hidden = tf.layers.dense(self.s, actor_hidden, tf.nn.relu6, kernel_initializer=w_init, name='hidden')\n",
        "            action_prob = tf.layers.dense(hidden, num_actions, tf.nn.softmax, kernel_initializer=w_init, name='action_prob')        \n",
        "        with tf.variable_scope('critic'):\n",
        "            hidden = tf.layers.dense(self.s, critic_hidden, tf.nn.relu6, kernel_initializer=w_init, name='hidden')\n",
        "            V = tf.layers.dense(hidden, 1, kernel_initializer=w_init, name='V')         \n",
        "        actor_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope + '/actor')\n",
        "        critic_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope + '/critic')       \n",
        "        return action_prob, V, actor_params, critic_params\n",
        "\n",
        "    def accumu_grad(self, OPT, loss, scope):\n",
        "        # retrieve trainable variables in scope of graph\n",
        "        #tvs = tf.trainable_variables(scope=scope + '/actor')\n",
        "        tvs = tf.trainable_variables(scope=scope)\n",
        "        # ceate a list of variables with the same shape as the trainable\n",
        "        accumu = [tf.Variable(tf.zeros_like(tv.initialized_value()), trainable=False) for tv in tvs]\n",
        "        zero_op = [tv.assign(tf.zeros_like(tv)) for tv in accumu] # initialized with 0s\n",
        "        gvs = OPT.compute_gradients(loss, tvs) # obtain list of gradients & variables\n",
        "        #gvs = [(tf.where( tf.is_nan(grad), tf.zeros_like(grad), grad ), var) for grad, var in gvs]\n",
        "        # adds to each element from the list you initialized earlier with zeros its gradient \n",
        "        # accumu and gvs are in same shape, index 0 is grads, index 1 is vars\n",
        "        accumu_op = [accumu[i].assign_add(gv[0]) for i, gv in enumerate(gvs)]\n",
        "        apply_op = OPT.apply_gradients([(accumu[i], gv[1]) for i, gv in enumerate(gvs)]) # apply grads\n",
        "        return zero_op, accumu_op, apply_op, accumu      \n",
        "      \n",
        "    def push_global_actor(self, feed_dict): \n",
        "        SESS = self.sess\n",
        "        SESS.run([self.push_actor_params], feed_dict)  \n",
        "\n",
        "    def push_global_critic(self, feed_dict):  \n",
        "        SESS = self.sess\n",
        "        SESS.run([self.push_critic_params], feed_dict)         \n",
        "        \n",
        "    def pull_global(self):  \n",
        "        SESS = self.sess\n",
        "        SESS.run([self.pull_actor_params, self.pull_critic_params])\n",
        "\n",
        "    def choose_action(self, s):  \n",
        "        SESS = self.sess\n",
        "        prob_weights = SESS.run(self.action_prob, feed_dict={self.s: s[None, :]})\n",
        "        action = np.random.choice(range(prob_weights.shape[1]), p=prob_weights.ravel()) \n",
        "        return action             \n",
        "        \n",
        "    def init_grad_storage_actor(self):\n",
        "        SESS = self.sess\n",
        "        SESS.run(self.actor_zero_op)\n",
        "        \n",
        "    def accumu_grad_actor(self, feed_dict):\n",
        "        SESS = self.sess\n",
        "        SESS.run([self.actor_accumu_op], feed_dict)          \n",
        "    \n",
        "    def apply_accumu_grad_actor(self, feed_dict):\n",
        "        SESS = self.sess\n",
        "        SESS.run([self.actor_apply_op], feed_dict)   \n",
        "        \n",
        "    def init_grad_storage_critic(self):\n",
        "        SESS = self.sess\n",
        "        SESS.run(self.critic_zero_op)\n",
        "        \n",
        "    def accumu_grad_critic(self, feed_dict):\n",
        "        SESS = self.sess\n",
        "        SESS.run([self.critic_accumu_op], feed_dict)          \n",
        "    \n",
        "    def apply_accumu_grad_critic(self, feed_dict):\n",
        "        SESS = self.sess\n",
        "        SESS.run([self.critic_apply_op], feed_dict)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRHGmXFpgOA2",
        "colab_type": "text"
      },
      "source": [
        "#Worker class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8n6s3a5qIvP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Worker(object): # local only\n",
        "    def __init__(self, name, globalAC, GLOBAL_EP, GLOBAL_RUNNING_R, sess):\n",
        "        self.env = gym.make(game)\n",
        "        self.name = name\n",
        "        self.AC = ACNet(name, sess, globalAC)\n",
        "        self.sess = sess\n",
        "        self.GLOBAL_EP = GLOBAL_EP\n",
        "        self.GLOBAL_RUNNING_R = GLOBAL_RUNNING_R\n",
        "        \n",
        "    def work(self):\n",
        "        #global GLOBAL_EP, GLOBAL_RUNNING_R\n",
        "        T = 0\n",
        "        t = 0\n",
        "        SESS = self.sess\n",
        "        GLOBAL_EP = self.GLOBAL_EP\n",
        "        GLOBAL_RUNNING_R = self.GLOBAL_RUNNING_R\n",
        "        \n",
        "        #while not COORD.should_stop() and GLOBAL_EP < max_global_episodes:\n",
        "        while SESS.run(GLOBAL_EP) < max_global_episodes:\n",
        "            s = self.env.reset()\n",
        "            ep_r = 0 # reward per episode\n",
        "            done = False\n",
        "            buffer_s, buffer_a, buffer_r, buffer_done = [], [], [], []\n",
        "            self.AC.pull_global()\n",
        "            while not done:\n",
        "                a = self.AC.choose_action(s)\n",
        "                s_, r, done, info = self.env.step(a)\n",
        "                ep_r += r\n",
        "                buffer_s.append(s)\n",
        "                buffer_a.append(a)\n",
        "                buffer_r.append(r)\n",
        "                buffer_done.append(done)                \n",
        "                s = s_\n",
        "                t += 1\n",
        "            \n",
        "            # if statement will always be done in this case... \n",
        "            # possible future modification\n",
        "            if done:\n",
        "                V_s = 0   \n",
        "            else:\n",
        "                V_s = SESS.run(self.AC.V, {self.AC.s: s[None, :]})[0, 0] # takes in just one s, not a batch.\n",
        "            \n",
        "            # critic related\n",
        "            critic_target = self.discount_rewards(buffer_r, GAMMA, V_s)\n",
        "            \n",
        "            buffer_s, buffer_a, critic_target = np.vstack(buffer_s), np.array(buffer_a), np.vstack(critic_target)\n",
        "            feed_dict = {self.AC.s: buffer_s, self.AC.critic_target: critic_target}                         \n",
        "            self.AC.accumu_grad_critic(feed_dict) # accumulating gradients for local critic  \n",
        "            self.AC.apply_accumu_grad_critic(feed_dict) \n",
        "            \n",
        "            baseline = SESS.run(self.AC.V, {self.AC.s: buffer_s}) # Value function\n",
        "            epr = np.vstack(buffer_r).astype(np.float32)\n",
        "            #V_s = SESS.run(self.AC.V, {self.AC.s: s[None, :]})[0, 0] # takes in just one s, not a batch.\n",
        "            #n_step_targets = self.n_step_targets_missing(epr, baseline, GAMMA, N_step) # Q values\n",
        "            n_step_targets = self.n_step_targets_max(epr, baseline, V_s, GAMMA, N_step) # Q values\n",
        "            # Advantage function\n",
        "            baselined_returns = n_step_targets - baseline\n",
        "\n",
        "            feed_dict = {self.AC.s: buffer_s, self.AC.a: buffer_a, self.AC.critic_target: critic_target, self.AC.baselined_returns: baselined_returns}            \n",
        "            self.AC.accumu_grad_actor(feed_dict) # accumulating gradients for local actor  \n",
        "            \n",
        "            # update\n",
        "            self.AC.push_global_actor(feed_dict)                \n",
        "            self.AC.push_global_critic(feed_dict)\n",
        "            buffer_s, buffer_a, buffer_r, buffer_done = [], [], [], []\n",
        "            self.AC.pull_global()\n",
        "              \n",
        "            if T % delay_rate == 0: # delay clearing of local gradients storage to reduce noise\n",
        "                # apply to local\n",
        "                self.AC.init_grad_storage_actor() # initialize storage for accumulated gradients.\n",
        "                self.AC.init_grad_storage_critic() \n",
        "                \n",
        "            #GLOBAL_EP += 1                   \n",
        "            SESS.run(GLOBAL_EP.assign_add(1.0))\n",
        "            #GLOBAL_RUNNING_R.append(ep_r) # for display\n",
        "            qe = GLOBAL_RUNNING_R.enqueue(ep_r)\n",
        "            SESS.run(qe)            \n",
        "            \n",
        "    def discount_rewards(self, r, gamma, running_add):\n",
        "      \"\"\"Take 1D float array of rewards and compute discounted reward \"\"\"\n",
        "      discounted_r = np.zeros_like(r)\n",
        "      #running_add = 0\n",
        "      for t in reversed(range(len(r))):\n",
        "          running_add = running_add * gamma + r[t]\n",
        "          discounted_r[t] = running_add\n",
        "      return discounted_r \n",
        "  \n",
        "    # As n increase, variance increase.\n",
        "    # Create a function that returns an array of n-step targets, one for each timestep:\n",
        "    # target[t] = r_t + \\gamma r_{t+1} + \\gamma^2 r_{t+2} + ... + \\gamma^n V(s_{t+n})\n",
        "    # Where r_t is given by episode reward (epr) and V(s_n) is given by the baselines.\n",
        "    \n",
        "    def n_step_targets_missing(self, epr, baselines, gamma, N):\n",
        "      targets = np.zeros_like(epr)    \n",
        "      if N > epr.size:\n",
        "        N = epr.size\n",
        "      for t in range(epr.size):    \n",
        "        for n in range(N):\n",
        "          if t+n == epr.size:            \n",
        "            break # missing terms treated as 0\n",
        "          if n == N-1: # last term\n",
        "            targets[t] += (gamma**n) * baselines[t+n]\n",
        "          else:\n",
        "            targets[t] += (gamma**n) * epr[t+n] \n",
        "      return targets  \n",
        "    \n",
        "    def n_step_targets_max(self, epr, baselines, v_s_, gamma, N):\n",
        "      targets = np.zeros_like(epr)    \n",
        "      if N > epr.size:\n",
        "        N = epr.size\n",
        "      for t in range(epr.size):  \n",
        "        #print(\"t=\", t)\n",
        "        for n in range(N):\n",
        "          #print(\"n=\", n)\n",
        "          if t+n == epr.size:            \n",
        "            targets[t] += (gamma**n) * v_s_ # use max steps available\n",
        "            break \n",
        "          if n == N-1: # last term\n",
        "            targets[t] += (gamma**n) * baselines[t+n]\n",
        "          else:\n",
        "            targets[t] += (gamma**n) * epr[t+n] \n",
        "      return targets     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "johkRuWNf7MU",
        "colab_type": "text"
      },
      "source": [
        "#Global variables & hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0nYHeKBL-D1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "game = 'CartPole-v0'\n",
        "#env = gym.make(game).unwrapped\n",
        "env = gym.make(game)\n",
        "\n",
        "num_obvs = env.observation_space.shape[0]\n",
        "num_actions = env.action_space.n\n",
        "\n",
        "net_scope = 'global'\n",
        "max_global_episodes = 500#5 #500\n",
        "delay_rate = 4000 # T steps\n",
        "\n",
        "GAMMA = 0.999 #0.99\n",
        "ENTROPY_BETA = 0.1 #0.01\n",
        "actor_alpha = 0.01   \n",
        "critic_alpha = 0.01   \n",
        "actor_hidden = 64#4 #128 #200\n",
        "critic_hidden = 64#4 #128 #200\n",
        "N_step = 15"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTiR3XvJgm3j",
        "colab_type": "text"
      },
      "source": [
        "#Setup cluster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bhd82T1eiWam",
        "colab": {}
      },
      "source": [
        "cluster = tf.train.ClusterSpec({\n",
        "    \"worker\": [\"localhost:2223\",\n",
        "               \"localhost:2224\"\n",
        "              ],\n",
        "    \"ps\": [\"localhost:2225\"]\n",
        "})\n",
        "\n",
        "def parameter_server():\n",
        "    #tf.reset_default_graph()\n",
        "    \n",
        "    server = tf.train.Server(cluster,\n",
        "                             job_name=\"ps\",\n",
        "                             task_index=0)\n",
        "    sess = tf.Session(target=server.target)        \n",
        "    \n",
        "    with tf.device(\"/job:ps/task:0\"):\n",
        "        GLOBAL_AC = ACNet(net_scope, sess, globalAC=None) # only need its params\n",
        "        GLOBAL_EP = tf.Variable(0.0, name='GLOBAL_EP') # num of global episodes   \n",
        "        # a queue of ep_r\n",
        "        GLOBAL_RUNNING_R = tf.FIFOQueue(max_global_episodes, tf.float32, shared_name=\"GLOBAL_RUNNING_R\")        \n",
        "    \n",
        "    print(\"Parameter server: waiting for cluster connection...\")\n",
        "    sess.run(tf.report_uninitialized_variables())\n",
        "    print(\"Parameter server: cluster ready!\")\n",
        "    \n",
        "    print(\"Parameter server: initializing variables...\")\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    print(\"Parameter server: variables initialized\")\n",
        "    \n",
        "    while True:\n",
        "        time.sleep(1.0)\n",
        "        #print(\"ps 1 GLOBAL_EP: \", sess.run(GLOBAL_EP))\n",
        "        #print(\"ps 1 GLOBAL_RUNNING_R.size(): \", sess.run(GLOBAL_RUNNING_R.size()))  \n",
        "        if sess.run(GLOBAL_RUNNING_R.size()) >= max_global_episodes: # GLOBAL_EP starts from 0, hence +1 to max_global_episodes          \n",
        "            time.sleep(5.0)\n",
        "            #print(\"ps 2 GLOBAL_RUNNING_R.size(): \", sess.run(GLOBAL_RUNNING_R.size()))  \n",
        "            GLOBAL_RUNNING_R_list = []\n",
        "            for j in range(sess.run(GLOBAL_RUNNING_R.size())):\n",
        "                ep_r = sess.run(GLOBAL_RUNNING_R.dequeue())\n",
        "                GLOBAL_RUNNING_R_list.append(ep_r) # for display\n",
        "            break\n",
        "              \n",
        "    # display\n",
        "    plt.plot(np.arange(len(GLOBAL_RUNNING_R_list)), GLOBAL_RUNNING_R_list)\n",
        "    plt.xlabel('episode')\n",
        "    plt.ylabel('reward')\n",
        "    plt.show()  \n",
        "\n",
        "    #print(\"Parameter server: blocking...\")\n",
        "    #server.join() # currently blocks forever    \n",
        "    print(\"Parameter server: ended...\")\n",
        "\n",
        "def worker(worker_n): \n",
        "    #tf.reset_default_graph()\n",
        "    \n",
        "    server = tf.train.Server(cluster,\n",
        "                             job_name=\"worker\",\n",
        "                             task_index=worker_n)\n",
        "    sess = tf.Session(target=server.target)  \n",
        "  \n",
        "    with tf.device(\"/job:ps/task:0\"):\n",
        "        GLOBAL_AC = ACNet(net_scope, sess, globalAC=None) # only need its params\n",
        "        GLOBAL_EP = tf.Variable(0.0, name='GLOBAL_EP') # num of global episodes\n",
        "        # a queue of ep_r\n",
        "        GLOBAL_RUNNING_R = tf.FIFOQueue(max_global_episodes, tf.float32, shared_name=\"GLOBAL_RUNNING_R\")   \n",
        "    \"\"\"\n",
        "    with tf.device(tf.train.replica_device_setter(\n",
        "                        worker_device='/job:worker/task:' + str(worker_n),\n",
        "                        cluster=cluster)):\n",
        "    \"\"\"                        \n",
        "    print(\"Worker %d: waiting for cluster connection...\" % worker_n)\n",
        "    sess.run(tf.report_uninitialized_variables())\n",
        "    print(\"Worker %d: cluster ready!\" % worker_n)\n",
        "    \n",
        "    #while sess.run(tf.report_uninitialized_variables()):\n",
        "    while (sess.run(tf.report_uninitialized_variables())).any(): # ********** .any() .all() **********\n",
        "        print(\"Worker %d: waiting for variable initialization...\" % worker_n)\n",
        "        time.sleep(1.0)\n",
        "    print(\"Worker %d: variables initialized\" % worker_n)\n",
        "    \n",
        "    w = Worker(str(worker_n), GLOBAL_AC, GLOBAL_EP, GLOBAL_RUNNING_R, sess) \n",
        "    print(\"Worker %d: created\" % worker_n)\n",
        "    \n",
        "    sess.run(tf.global_variables_initializer()) # got to initialize after Worker creation\n",
        "    w.work()\n",
        "    print(\"Worker %d: w.work()\" % worker_n)\n",
        "          \n",
        "    #print(\"Worker %d: blocking...\" % worker_n)\n",
        "    server.join() # currently blocks forever\n",
        "    print(\"Worker %d: ended...\" % worker_n)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7aQb49JkRPC",
        "colab_type": "text"
      },
      "source": [
        "#Setup processes, rollout & train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfeXcrPCkON6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b54810e1-511e-49a5-f051-0490210fc94b"
      },
      "source": [
        "start_time = time.time()\n",
        "\n",
        "ps_proc = Process(target=parameter_server, daemon=True)\n",
        "w1_proc = Process(target=worker, args=(0, ), daemon=True)\n",
        "w2_proc = Process(target=worker, args=(1, ), daemon=True)\n",
        "\n",
        "ps_proc.start()\n",
        "w1_proc.start()\n",
        "w2_proc.start()\n",
        "\n",
        "# if not join, parent will terminate before children \n",
        "# & children will terminate as well cuz children are daemon\n",
        "ps_proc.join() \n",
        "#w1_proc.join()\n",
        "#w2_proc.join() \n",
        "    \n",
        "for proc in [w1_proc, w2_proc, ps_proc]:\n",
        "    proc.terminate() # only way to kill server is to kill it's process\n",
        "        \n",
        "print('All done.')     \n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))    "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-dec5e8c17b0c>:49: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.WARNING:tensorflow:From <ipython-input-3-dec5e8c17b0c>:49: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From <ipython-input-3-dec5e8c17b0c>:49: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "\n",
            "Worker 1: waiting for cluster connection...\n",
            "Parameter server: waiting for cluster connection...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Worker 0: waiting for cluster connection...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.whereWorker 1: cluster ready!\n",
            "Parameter server: cluster ready!\n",
            "\n",
            "Parameter server: initializing variables...\n",
            "Parameter server: variables initialized\n",
            "Worker 0: cluster ready!\n",
            "Worker 1: variables initialized\n",
            "Worker 0: variables initialized\n",
            "WARNING:tensorflow:From <ipython-input-3-dec5e8c17b0c>:24: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From <ipython-input-3-dec5e8c17b0c>:63: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From <ipython-input-3-dec5e8c17b0c>:24: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From <ipython-input-3-dec5e8c17b0c>:63: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "Worker 1: created\n",
            "Worker 0: created\n",
            "Worker 0: w.work()\n",
            "Worker 1: w.work()\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Parameter server: ended...\n",
            "All done.\n",
            "--- 166.8326187133789 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}