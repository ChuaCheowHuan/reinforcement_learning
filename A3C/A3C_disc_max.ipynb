{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A3C_disc_max.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmiXBukYvLDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "A3C (Asynchronous Advantage Actor Critic) implementation with Tensorflow \n",
        "with N step targets (use maximum terms possible). This is a multi-threaded \n",
        "discrete version. The code is tested with Gymâ€™s discrete action space \n",
        "environment, CartPole-v0 on Colab.\n",
        "\"\"\"\n",
        "\n",
        "import threading\n",
        "import multiprocessing\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import gym\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQso0DMQvaZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ACNet(object):\n",
        "    def __init__(self, scope, globalAC=None):\n",
        "        if scope == net_scope: # global\n",
        "            with tf.variable_scope(scope):\n",
        "                self.s = tf.placeholder(tf.float32, [None, num_obvs], 'S')\n",
        "                # create global net\n",
        "                self.actor_params, self.critic_params = self._create_net(scope)[-2:] # only require params\n",
        "                \n",
        "        else: # local\n",
        "            with tf.variable_scope(scope):\n",
        "                self.s = tf.placeholder(tf.float32, [None, num_obvs], 'S')\n",
        "                self.a = tf.placeholder(tf.int32, [None, ], 'A')\n",
        "                self.critic_target = tf.placeholder(tf.float32, [None, 1], 'critic_target')\n",
        "                self.baselined_returns = tf.placeholder(tf.float32, [None, 1], 'baselined_returns') # for calculating advantage \n",
        "                # create local net\n",
        "                self.action_prob, self.V, self.actor_params, self.critic_params = self._create_net(scope)\n",
        "                    \n",
        "                TD_err = tf.subtract(self.critic_target, self.V, name='TD_err')\n",
        "                with tf.name_scope('actor_loss'):\n",
        "                    log_prob = tf.reduce_sum(tf.log(self.action_prob + 1e-5) * tf.one_hot(self.a, num_actions, dtype=tf.float32), axis=1, keep_dims=True)\n",
        "                    actor_component = log_prob * tf.stop_gradient(self.baselined_returns)\n",
        "                    # entropy for exploration\n",
        "                    entropy = -tf.reduce_sum(self.action_prob * tf.log(self.action_prob + 1e-5), axis=1, keep_dims=True)  # encourage exploration\n",
        "                    self.actor_loss = tf.reduce_mean( -(ENTROPY_BETA * entropy + actor_component) )                                        \n",
        "                with tf.name_scope('critic_loss'):\n",
        "                    self.critic_loss = tf.reduce_mean(tf.square(TD_err))                      \n",
        "                # accumulated gradients for local actor    \n",
        "                with tf.name_scope('local_actor_grad'):                   \n",
        "                    self.actor_zero_op, self.actor_accumu_op, self.actor_apply_op, actor_accum = self.accumu_grad(OPT_A, self.actor_loss, scope=scope + '/actor')\n",
        "                # accumulated gradients for local critic    \n",
        "                with tf.name_scope('local_critic_grad'):\n",
        "                    self.critic_zero_op, self.critic_accumu_op, self.critic_apply_op, critic_accum = self.accumu_grad(OPT_C, self.critic_loss, scope=scope + '/critic')\n",
        "                    \n",
        "            with tf.name_scope('params'): # push/pull from local/worker perspective\n",
        "                with tf.name_scope('push_to_global'):\n",
        "                    self.push_actor_params = OPT_A.apply_gradients(zip(actor_accum, globalAC.actor_params))\n",
        "                    self.push_critic_params = OPT_C.apply_gradients(zip(critic_accum, globalAC.critic_params))\n",
        "                with tf.name_scope('pull_fr_global'):\n",
        "                    self.pull_actor_params = [local_params.assign(global_params) for local_params, global_params in zip(self.actor_params, globalAC.actor_params)]\n",
        "                    self.pull_critic_params = [local_params.assign(global_params) for local_params, global_params in zip(self.critic_params, globalAC.critic_params)]                    \n",
        "                    \n",
        "    def _create_net(self, scope):\n",
        "        w_init = tf.glorot_uniform_initializer()\n",
        "        with tf.variable_scope('actor'):\n",
        "            hidden = tf.layers.dense(self.s, actor_hidden, tf.nn.relu6, kernel_initializer=w_init, name='hidden')\n",
        "            action_prob = tf.layers.dense(hidden, num_actions, tf.nn.softmax, kernel_initializer=w_init, name='action_prob')        \n",
        "        with tf.variable_scope('critic'):\n",
        "            hidden = tf.layers.dense(self.s, critic_hidden, tf.nn.relu6, kernel_initializer=w_init, name='hidden')\n",
        "            V = tf.layers.dense(hidden, 1, kernel_initializer=w_init, name='V')         \n",
        "        actor_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope + '/actor')\n",
        "        critic_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope + '/critic')       \n",
        "        return action_prob, V, actor_params, critic_params\n",
        "\n",
        "    def accumu_grad(self, OPT, loss, scope):\n",
        "        # retrieve trainable variables in scope of graph\n",
        "        #tvs = tf.trainable_variables(scope=scope + '/actor')\n",
        "        tvs = tf.trainable_variables(scope=scope)\n",
        "        # ceate a list of variables with the same shape as the trainable\n",
        "        accumu = [tf.Variable(tf.zeros_like(tv.initialized_value()), trainable=False) for tv in tvs]\n",
        "        zero_op = [tv.assign(tf.zeros_like(tv)) for tv in accumu] # initialized with 0s\n",
        "        gvs = OPT.compute_gradients(loss, tvs) # obtain list of gradients & variables\n",
        "        #gvs = [(tf.where( tf.is_nan(grad), tf.zeros_like(grad), grad ), var) for grad, var in gvs]\n",
        "        # adds to each element from the list you initialized earlier with zeros its gradient \n",
        "        # accumu and gvs are in same shape, index 0 is grads, index 1 is vars\n",
        "        accumu_op = [accumu[i].assign_add(gv[0]) for i, gv in enumerate(gvs)]\n",
        "        apply_op = OPT.apply_gradients([(accumu[i], gv[1]) for i, gv in enumerate(gvs)]) # apply grads\n",
        "        return zero_op, accumu_op, apply_op, accumu      \n",
        "      \n",
        "    def push_global_actor(self, feed_dict):  \n",
        "        SESS.run([self.push_actor_params], feed_dict)  \n",
        "\n",
        "    def push_global_critic(self, feed_dict):  \n",
        "        SESS.run([self.push_critic_params], feed_dict)         \n",
        "        \n",
        "    def pull_global(self):  \n",
        "        SESS.run([self.pull_actor_params, self.pull_critic_params])\n",
        "\n",
        "    def choose_action(self, s):  \n",
        "        prob_weights = SESS.run(self.action_prob, feed_dict={self.s: s[None, :]})\n",
        "        action = np.random.choice(range(prob_weights.shape[1]), p=prob_weights.ravel()) \n",
        "        return action             \n",
        "        \n",
        "    def init_grad_storage_actor(self):\n",
        "        SESS.run(self.actor_zero_op)\n",
        "        \n",
        "    def accumu_grad_actor(self, feed_dict):\n",
        "        SESS.run([self.actor_accumu_op], feed_dict)          \n",
        "    \n",
        "    def apply_accumu_grad_actor(self, feed_dict):\n",
        "        SESS.run([self.actor_apply_op], feed_dict)   \n",
        "        \n",
        "    def init_grad_storage_critic(self):\n",
        "        SESS.run(self.critic_zero_op)\n",
        "        \n",
        "    def accumu_grad_critic(self, feed_dict):\n",
        "        SESS.run([self.critic_accumu_op], feed_dict)          \n",
        "    \n",
        "    def apply_accumu_grad_critic(self, feed_dict):\n",
        "        SESS.run([self.critic_apply_op], feed_dict)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8n6s3a5qIvP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Worker(object): # local only\n",
        "    def __init__(self, name, globalAC):\n",
        "        self.env = gym.make(game)\n",
        "        self.name = name\n",
        "        self.AC = ACNet(name, globalAC)\n",
        "    def work(self):\n",
        "        global GLOBAL_RUNNING_R, GLOBAL_EP\n",
        "        T = 0\n",
        "        t = 0\n",
        "        while not COORD.should_stop() and GLOBAL_EP < max_global_episodes:\n",
        "            s = self.env.reset()\n",
        "            ep_r = 0 # reward per episode\n",
        "            done = False\n",
        "            buffer_s, buffer_a, buffer_r, buffer_done = [], [], [], []\n",
        "            self.AC.pull_global()\n",
        "            while not done:\n",
        "                a = self.AC.choose_action(s)\n",
        "                s_, r, done, info = self.env.step(a)\n",
        "                ep_r += r\n",
        "                buffer_s.append(s)\n",
        "                buffer_a.append(a)\n",
        "                buffer_r.append(r)\n",
        "                buffer_done.append(done)                \n",
        "                s = s_\n",
        "                t += 1\n",
        "            \n",
        "            # if statement will always be done in this case... \n",
        "            # possible future modification\n",
        "            if done:\n",
        "                V_s = 0   \n",
        "            else:\n",
        "                V_s = SESS.run(self.AC.V, {self.AC.s: s[None, :]})[0, 0] # takes in just one s, not a batch.\n",
        "            \n",
        "            # critic related\n",
        "            critic_target = self.discount_rewards(buffer_r, GAMMA, V_s)\n",
        "            \n",
        "            buffer_s, buffer_a, critic_target = np.vstack(buffer_s), np.array(buffer_a), np.vstack(critic_target)\n",
        "            feed_dict = {self.AC.s: buffer_s, self.AC.critic_target: critic_target}                         \n",
        "            self.AC.accumu_grad_critic(feed_dict) # accumulating gradients for local critic  \n",
        "            self.AC.apply_accumu_grad_critic(feed_dict) \n",
        "            \n",
        "            baseline = SESS.run(self.AC.V, {self.AC.s: buffer_s}) # Value function\n",
        "            epr = np.vstack(buffer_r).astype(np.float32)\n",
        "            #V_s = SESS.run(self.AC.V, {self.AC.s: s[None, :]})[0, 0] # takes in just one s, not a batch.\n",
        "            n_step_targets = self.n_step_targets_max(epr, baseline, V_s, GAMMA, N_step) # Q values\n",
        "            # Advantage function\n",
        "            baselined_returns = n_step_targets - baseline\n",
        "\n",
        "            feed_dict = {self.AC.s: buffer_s, self.AC.a: buffer_a, self.AC.critic_target: critic_target, self.AC.baselined_returns: baselined_returns}            \n",
        "            self.AC.accumu_grad_actor(feed_dict) # accumulating gradients for local actor  \n",
        "            \n",
        "            # update\n",
        "            self.AC.push_global_actor(feed_dict)                \n",
        "            self.AC.push_global_critic(feed_dict)\n",
        "            buffer_s, buffer_a, buffer_r, buffer_done = [], [], [], []\n",
        "            self.AC.pull_global()\n",
        "              \n",
        "            #if T % delay_rate == 0: # delay clearing of local gradients storage to reduce noise\n",
        "                # apply to local\n",
        "                #self.AC.init_grad_storage_actor() # initialize storage for accumulated gradients.\n",
        "                #self.AC.init_grad_storage_critic() \n",
        "                \n",
        "            self.AC.init_grad_storage_actor() # initialize storage for accumulated gradients.\n",
        "            self.AC.init_grad_storage_critic() \n",
        "            \n",
        "            GLOBAL_RUNNING_R.append(ep_r) # for display\n",
        "            GLOBAL_EP += 1                           \n",
        "      \n",
        "    def discount_rewards(self, r, gamma, running_add):\n",
        "      \"\"\"Take 1D float array of rewards and compute discounted reward \"\"\"\n",
        "      discounted_r = np.zeros_like(r)\n",
        "      #running_add = 0\n",
        "      for t in reversed(range(len(r))):\n",
        "          running_add = running_add * gamma + r[t]\n",
        "          discounted_r[t] = running_add\n",
        "      return discounted_r \n",
        "  \n",
        "    # As n increase, variance increase.\n",
        "    # Create a function that returns an array of n-step targets, one for each timestep:\n",
        "    # target[t] = r_t + \\gamma r_{t+1} + \\gamma^2 r_{t+2} + ... + \\gamma^n V(s_{t+n})\n",
        "    # Where r_t is given by episode reward (epr) and V(s_n) is given by the baselines.\n",
        "    \"\"\"\n",
        "    def n_step_targets_missing(self, epr, baselines, gamma, N):\n",
        "      targets = np.zeros_like(epr)    \n",
        "      if N > epr.size:\n",
        "        N = epr.size\n",
        "      for t in range(epr.size):    \n",
        "        for n in range(N):\n",
        "          if t+n == epr.size:            \n",
        "            break # missing terms treated as 0\n",
        "          if n == N-1: # last term\n",
        "            targets[t] += (gamma**n) * baselines[t+n]\n",
        "          else:\n",
        "            targets[t] += (gamma**n) * epr[t+n] \n",
        "      return targets  \n",
        "    \"\"\"\n",
        "    def n_step_targets_max(self, epr, baselines, v_s_, gamma, N):\n",
        "      targets = np.zeros_like(epr)    \n",
        "      if N > epr.size:\n",
        "        N = epr.size\n",
        "      for t in range(epr.size):  \n",
        "        #print(\"t=\", t)\n",
        "        for n in range(N):\n",
        "          #print(\"n=\", n)\n",
        "          if t+n == epr.size:            \n",
        "            targets[t] += (gamma**n) * v_s_ # use max steps available\n",
        "            break \n",
        "          if n == N-1: # last term\n",
        "            targets[t] += (gamma**n) * baselines[t+n]\n",
        "          else:\n",
        "            targets[t] += (gamma**n) * epr[t+n] \n",
        "      return targets \n",
        "    \"\"\"\n",
        "    def n_step_targets_3(self, r, B, g, N):\n",
        "      if N >= len(r):\n",
        "        N = len(r)-1\n",
        "      \n",
        "      T = np.zeros_like(r)             \n",
        "    \n",
        "      # Non n-steps ops without baseline terms\n",
        "      t = r.size-1\n",
        "      T[t] = r[t] # last entry, do 0 step\n",
        "      for n in range(1,N): # n = 1..N-1, do 1 step to N-1 step\n",
        "        t = t-1\n",
        "        for i in range(n): # get 0..n-1 gamma raised r terms\n",
        "          T[t] += g**i * r[t+i] \n",
        "    \n",
        "      # Non n-steps ops with baseline terms\n",
        "      t = r.size-1\n",
        "      for j in range(1,N): # 1..N-1\n",
        "        t = t-1\n",
        "        T[t] += g**j * B[N]\n",
        "    \n",
        "      # n-steps ops without baseline\n",
        "      for t in range(r.size-N): # 0..r.size-N-1\n",
        "        for k in range(N):\n",
        "          T[t] += g**k * r[t+k] \n",
        "    \n",
        "      # n-steps ops with baseline\n",
        "      for t in range(r.size-N): # 0..r.size-N-1\n",
        "        T[t] += g**N * B[t+N]\n",
        "    \n",
        "      return T \n",
        "    \"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8Y3NFAbZq1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "game = 'CartPole-v0'\n",
        "#env = gym.make(game).unwrapped\n",
        "env = gym.make(game)\n",
        "\n",
        "num_obvs = env.observation_space.shape[0]\n",
        "num_actions = env.action_space.n\n",
        "\n",
        "net_scope = 'global'\n",
        "max_global_episodes = 500\n",
        "delay_rate = 4000 # T steps\n",
        "\n",
        "#num_workers = multiprocessing.cpu_count()\n",
        "num_workers = 4 #16\n",
        "\n",
        "GAMMA = 0.999 #0.99\n",
        "ENTROPY_BETA = 0.1 #0.01\n",
        "actor_alpha = 0.01   \n",
        "critic_alpha = 0.01   \n",
        "actor_hidden = 128 #200\n",
        "critic_hidden = 128 #200\n",
        "N_step = 15"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcrwcW1f01-z",
        "colab_type": "code",
        "outputId": "13b1aeb9-0cc9-4421-f23a-7d1cf2d8b909",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        }
      },
      "source": [
        "start_time = time.time()\n",
        "\n",
        "SESS = tf.Session()   \n",
        "with tf.device(\"/cpu:0\"):\n",
        "    OPT_A = tf.train.AdamOptimizer(actor_alpha, beta1=0.99, beta2=0.999, name='OPT_A')\n",
        "    OPT_C = tf.train.AdamOptimizer(critic_alpha, beta1=0.99, beta2=0.999, name='OPT_C')\n",
        "\n",
        "    # globalAC=None, GLOBAL_AC is already the only global AC net.\n",
        "    GLOBAL_AC = ACNet(net_scope, globalAC=None) # only need its params\n",
        "    workers = []\n",
        "    for i in range(num_workers): # Create worker\n",
        "        i_name = 'W_%i' % i # worker name\n",
        "        workers.append(Worker(i_name, GLOBAL_AC))   \n",
        "        \n",
        "    GLOBAL_RUNNING_R = []\n",
        "    GLOBAL_EP = 0\n",
        "        \n",
        "    COORD = tf.train.Coordinator()\n",
        "    SESS.run(tf.global_variables_initializer())\n",
        "            \n",
        "    worker_threads = []\n",
        "    for worker in workers:\n",
        "        job = lambda: worker.work()\n",
        "        t = threading.Thread(target=job)\n",
        "        t.start()\n",
        "        worker_threads.append(t)\n",
        "    COORD.join(worker_threads)\n",
        "    \n",
        "    # display\n",
        "    plt.plot(np.arange(len(GLOBAL_RUNNING_R)), GLOBAL_RUNNING_R)\n",
        "    plt.xlabel('episode')\n",
        "    plt.ylabel('reward')\n",
        "    plt.show()         \n",
        "    \n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0617 13:48:12.233595 140326032390016 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0617 13:48:12.235539 140326032390016 deprecation.py:323] From <ipython-input-2-1ca1304e401c>:45: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "W0617 13:48:12.699820 140326032390016 deprecation.py:506] From <ipython-input-2-1ca1304e401c>:20: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "W0617 13:48:12.718672 140326032390016 deprecation.py:323] From <ipython-input-2-1ca1304e401c>:59: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "--- 45.205078125 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}